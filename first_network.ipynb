{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ") \n",
    "\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_data_loader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for x, y in test_data_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(y.dtype)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, loss_fn, optimizer):\n",
    "    size = len(data_loader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(data_loader):\n",
    "        prediction = model(x)\n",
    "        loss = loss_fn(prediction, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(loss.item(), (batch + 1) * len(x), size)\n",
    "\n",
    "def test(data_loader, model, loss_fn):\n",
    "    size = len(data_loader.dataset)\n",
    "    num_batches = len(data_loader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(correct, test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1\n",
      "2.30128812789917 64 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2812867164611816 6464 60000\n",
      "2.2644267082214355 12864 60000\n",
      "2.2592504024505615 19264 60000\n",
      "2.234238624572754 25664 60000\n",
      "2.208918571472168 32064 60000\n",
      "2.218365430831909 38464 60000\n",
      "2.178802967071533 44864 60000\n",
      "2.175074338912964 51264 60000\n",
      "2.143059253692627 57664 60000\n",
      "0.4244 2.132374804490691\n",
      "Epoch number 2\n",
      "2.1429049968719482 64 60000\n",
      "2.1257691383361816 6464 60000\n",
      "2.0662953853607178 12864 60000\n",
      "2.0893545150756836 19264 60000\n",
      "2.032365322113037 25664 60000\n",
      "1.9657355546951294 32064 60000\n",
      "2.0042550563812256 38464 60000\n",
      "1.913061499595642 44864 60000\n",
      "1.9214746952056885 51264 60000\n",
      "1.849424958229065 57664 60000\n",
      "0.5528 1.843077358166883\n",
      "Epoch number 3\n",
      "1.8790148496627808 64 60000\n",
      "1.837816834449768 6464 60000\n",
      "1.7205452919006348 12864 60000\n",
      "1.7768476009368896 19264 60000\n",
      "1.676139235496521 25664 60000\n",
      "1.6176562309265137 32064 60000\n",
      "1.6581358909606934 38464 60000\n",
      "1.5526419878005981 44864 60000\n",
      "1.581667423248291 51264 60000\n",
      "1.4815558195114136 57664 60000\n",
      "0.607 1.4953518756635629\n",
      "Epoch number 4\n",
      "1.563630223274231 64 60000\n",
      "1.5215681791305542 6464 60000\n",
      "1.3777470588684082 12864 60000\n",
      "1.4605321884155273 19264 60000\n",
      "1.354251742362976 25664 60000\n",
      "1.3344734907150269 32064 60000\n",
      "1.3658668994903564 38464 60000\n",
      "1.285036325454712 44864 60000\n",
      "1.3169267177581787 51264 60000\n",
      "1.2250722646713257 57664 60000\n",
      "0.6275 1.2463914846918385\n",
      "Epoch number 5\n",
      "1.321723461151123 64 60000\n",
      "1.2962558269500732 6464 60000\n",
      "1.139724612236023 12864 60000\n",
      "1.2525616884231567 19264 60000\n",
      "1.1357461214065552 25664 60000\n",
      "1.1454817056655884 32064 60000\n",
      "1.1814674139022827 38464 60000\n",
      "1.1143391132354736 44864 60000\n",
      "1.1471949815750122 51264 60000\n",
      "1.0698988437652588 57664 60000\n",
      "0.6439 1.087063079047355\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "for t in range(1, EPOCH + 1):\n",
    "    print(f'Epoch number {t}')\n",
    "    train(\n",
    "        train_data_loader,\n",
    "        model,\n",
    "        loss_fn,\n",
    "        optimizer\n",
    "    )\n",
    "    test(\n",
    "        test_data_loader,\n",
    "        model,\n",
    "        loss_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Ankle boot, Actual: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: {predicted}, Actual: {actual}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "flower"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
